{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SparkR Adapted Code for DataPreprocessing_New.R\n",
    "\n",
    "## Notes:\n",
    "## 1. Most optimizations in this file are using spark.lapply (in place of native R functions)\n",
    "## 2. To look into - can I use dapply or dApply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#' Function that drops non numerical data (not necessary for analysis) from the datasets\n",
    "#' \n",
    "#' @param datasetsList_old a list of the discrete and continuous datasets of the form \n",
    "#' list(\"discrete\" = discrete_dataset, \"continuous\" = continuous_dataset) (to be obtained from \\code{addIdentifyingInfo}\n",
    "#'  in \\code{DataSeparation_New.R})\n",
    "#'  \n",
    "#' @return a similar list like the parameter passed in, with non-numerical data removed\n",
    "#'  \n",
    "#' @example \n",
    "#' data = loadData(dataset_file_path)\n",
    "#' indices = getDiscreteAndContinuousIndices(dataset)\n",
    "#' new_data = addIdentifyingInfo(data, indices)\n",
    "#' dropNonNumericalData(new_data)\n",
    "dropNonNumericalData <- function(datasetsList_old) {\n",
    "  \n",
    "  ## Exclude unecessary (the two specific) columns\n",
    "  ## @TODO: remove hardcoded (dataset-specfic) values here\n",
    "  continuous_dataset = datasetsList_old$continuous[-1, c(-1,-2)]\n",
    "  discrete_dataset = datasetsList_old$discrete[-1, ]\n",
    "  \n",
    "  ## Pack into a list, and return\n",
    "  datasetsList_new = list(\"discrete\" = discrete_dataset, \"continuous\" = continuous_dataset)\n",
    "  return(datasetsList_new)\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#' Function that gets the percentage of missing data in the columns of a dataset\n",
    "#' Helper function for \\code{dropColumnsWithMissingData}\n",
    "#' \n",
    "#' @param dataset a dataframe\n",
    "#' \n",
    "#' @return a list of the percentages of missing data in every column\n",
    "#' \n",
    "#' @example \n",
    "#' missingPercent(datasetsList$discrete)\n",
    "missingPercent <- function(dataset) {\n",
    "  \n",
    "  return(spark.lapply(dataset, function(n) sum(is.na(n))/(length(n))))\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#' Function that drops columns in the discrete and continuous datasets which have missing data percentage\n",
    "#' above a provided threshold\n",
    "#' \n",
    "#' @param missingDataThreshold the threshold of missing data in a column for which that data should be removed\n",
    "#' @param datasetsList_old list of the discrete and continuous datasets\n",
    "#' \n",
    "#' @return a similar list like the parameter passed in, with columns having too much missing data removed\n",
    "#' \n",
    "#' @example \n",
    "#' dropColumnsWithMissingData(0.60, datasets)\n",
    "dropColumnsWithMissingData <- function(missingDataThreshold, datasetsList_old) {\n",
    "  \n",
    "  ## Compute the % of Missing Data for each column in the two Datasets\n",
    "  missing_stats_for_discrete = unlist(missingPercent(datasetsList_old$discrete))\n",
    "  missing_stats_for_continuous = unlist(missingPercent(datasetsList_old$continuous))\n",
    "  \n",
    "  ##Filter out Columns with Missing Data above a Provided Threshold\n",
    "  discrete_dataset = datasetsList_old$discrete[ , which(missing_stats_for_discrete < missingDataThreshold)]\n",
    "  continuous_dataset = datasetsList_old$continuous[ , which(missing_stats_for_continuous < missingDataThreshold)]\n",
    "  \n",
    "  ## Pack into a list, and return\n",
    "  datasetsList_new = list(\"discrete\" = discrete_dataset, \"continuous\" = continuous_dataset)\n",
    "  return(datasetsList_new)\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#' Function that converts all the data in both datasets to be of uniform data type (double)\n",
    "#' \n",
    "#' @param datasetsList_old a list of the discrete and continuous datasets of the form \n",
    "#' list(\"discrete\" = discrete_dataset, \"continuous\" = continuous_dataset)\n",
    "#' \n",
    "#' @return a similar list like the parameter passed in, with uniform data types\n",
    "#' \n",
    "#' @example\n",
    "#' makeDataTypesUniform(datasetsList)\n",
    "makeDataTypesUniform <- function(datasetsList_old) {\n",
    "  \n",
    "  ## Convert the data type to double for both discrete and continuous datasets\n",
    "  discrete_dataset = as.data.frame(spark.lapply(datasetsList_old$discrete, function(x) as.double(as.character(x))))\n",
    "  continuous_dataset = as.data.frame(spark.lapply(datasetsList_old$continuous, function(x) as.double(as.character(x))))\n",
    "  \n",
    "  ## Pack into a list, and return\n",
    "  datasetsList_new = list(\"discrete\" = discrete_dataset, \"continuous\" = continuous_dataset)\n",
    "  return(datasetsList_new)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#' Function that drops rows in the discrete and continuous datasets which have missing data percentage\n",
    "#' above a provided threshold\n",
    "#' \n",
    "#' @param missingDataThreshold the threshold of missing data in a row for which that data should be removed\n",
    "#' @param datasetsList_old list of the discrete and continuous datasets\n",
    "#' \n",
    "#' @return a similar list like the parameter passed in, with rows having too much missing data removed\n",
    "#' \n",
    "#' @example \n",
    "#' dropRowsWithMissingData(0.60, datasets)\n",
    "dropRowsWithMissingData <- function(missingDataThreshold, datasetsList_old) {\n",
    "  \n",
    "  ## Calculate amount of missing data in the rows of discrete dataset, then delete them depending upon\n",
    "  ## the threshold.\n",
    "  missing_stats_for_discrete = rowSums(is.na(datasetsList_old$discrete), na.rm = TRUE) / ncol(datasetsList_old$discrete)\n",
    "  discrete_dataset = datasetsList_old$discrete[which(missing_stats_for_discrete < missingDataThreshold), ]\n",
    "  \n",
    "  ## Calculate amount of missing data in the rows of continuous dataset, then delete them depending upon\n",
    "  ## the threshold.\n",
    "  missing_stats_for_continuous = rowSums(is.na(datasetsList_old$continuous), na.rm = TRUE) / ncol(datasetsList_old$continuous)\n",
    "  continuous_dataset = datasetsList_old$continuous[which(missing_stats_for_continuous < missingDataThreshold), ]\n",
    "  \n",
    "  ## Pack into a list, and return\n",
    "  datasetsList_new = list(\"discrete\" = discrete_dataset, \"continuous\" = continuous_dataset)\n",
    "  return(datasetsList_new)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper Function\n",
    "## Normalizes a given column's data\n",
    "\n",
    "#' Function that normalizes data in the column of a dataset\n",
    "#' Helper function for \\code{normalizeContinuousData}\n",
    "#' \n",
    "#' @param n a dataframe column\n",
    "#' \n",
    "#' @return the column, with data normalized\n",
    "#' \n",
    "#' @example \n",
    "#' lapply(continuousDataset, normalizeCol)\n",
    "normalizeCol <- function(n) {\n",
    "  \n",
    "  return(n/mean(n, na.rm = TRUE))\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize the data in the Continuous Dataset\n",
    "\n",
    "#' Function that normalizes all the data in the continuous dataset\n",
    "#' \n",
    "#' @param continuousDataset the dataset containing continuous data\n",
    "#' \n",
    "#' @return the dataset, normalized\n",
    "#' \n",
    "#' @example \n",
    "#' normalizeContinuousData(datasetsList$continuous)\n",
    "normalizeContinuousData <- function(continuousDataset) {\n",
    "  \n",
    "  ## Normalizes each column in the continuous dataset\n",
    "  continuousDatasetNormalized = as.data.frame(spark.lapply(continuousDataset, normalizeCol))\n",
    "  \n",
    "  ## Return the normalized dataset\n",
    "  return(continuousDatasetNormalized)\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
